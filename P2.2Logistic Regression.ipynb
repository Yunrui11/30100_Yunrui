{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Modles \n",
    "\n",
    "- explore logistic regression with l1 and l2 penalty, and different magnitude of C values\n",
    "- explore other parameter settings that could potentially affect your model performance, find a model that works best on your data\n",
    "- interpret model performance and discuss pros and cons of each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Link of my dataset: https://www.kaggle.com/datasets/infamouscoder/depression-reddit-cleaned *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file to a pandas dataframe\n",
    "path = '/Users/pro/Desktop/Winter 2024/30100/30100_Yunrui/Reddit_depression.csv'\n",
    "df = pd.read_csv(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7731, 2)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the data frame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  is_depression\n",
       "0  we understand that most people who reply immed...              1\n",
       "1  welcome to r depression s check in post a plac...              1\n",
       "2  anyone else instead of sleeping more when depr...              1\n",
       "3  i ve kind of stuffed around a lot in my life d...              1\n",
       "4  sleep is my greatest and most comforting escap...              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an overview of the top-n rows/samples\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  is_depression\n",
       "0  we understand that most people who reply immed...              1\n",
       "1  welcome to r depression s check in post a plac...              1\n",
       "2  anyone else instead of sleeping more when depr...              1\n",
       "3  i ve kind of stuffed around a lot in my life d...              1\n",
       "4  sleep is my greatest and most comforting escap...              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text       0\n",
       "is_depression    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this dataset has been cleaned, so there is no missing value\n",
    "null_sum = df.isnull().sum()\n",
    "null_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text       object\n",
       "is_depression     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data type of each column\n",
    "# find out the clean_text is not string type, but we need string for text analysis\n",
    "df.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text       string[python]\n",
       "is_depression             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert clean_text to string type\n",
    "df['clean_text'] = df['clean_text'].astype('string')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='is_depression', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this indicates that our dataset is pretty balanced\n",
    "sns.countplot(data=df,x=\"is_depression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text transformation \n",
    "- tokenization, stemming, lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case all words\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabetic(text):\n",
    "    return ''.join(char if char.isalpha() or char.isspace() else '' for char in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i ve kind of stuffed around a lot in my life delaying the inevitable of having to work a job and be a responsible adult and i m but the longest i ve ever held a job wa  month it wasn t that i m lazy i wa always doing other thing i enjoy but i know now unemployment ha caused most of my depression recently i just feel utterly hopeless when i think soon enough i ll have to move out on my own in some shitty house working a job i couldn t care le about to me it just seems like the perfect recipe to depression'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove non alphabetic characters\n",
    "# wwe also see that the sentence has been stemmed, we only need to lemmatize it\n",
    "df['clean_text'] = df['clean_text'].apply(remove_non_alphabetic)\n",
    "df['clean_text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize, lemmatize the text\n",
    "text_lst = []\n",
    "for i in df['clean_text']:\n",
    "    tokens = word_tokenize(i)\n",
    "    text = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    text = \" \".join(text)\n",
    "    text_lst.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7731"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "- CountVectorizer\n",
    "- TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CountVectorizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, max_df=0.8,ngram_range=(1,1),binary=False,stop_words='english',max_features=1000)\n",
    "X = vectorizer.fit_transform(text_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7731, 1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the feature matrix of the vectorized corpus\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'absolutely', 'abuse', 'abusive', 'accept', 'accident',\n",
       "       'account', 'act', 'action', 'actually', 'add', 'adhd', 'adult',\n",
       "       'advice', 'affect', 'afford', 'afraid', 'age', 'ago', 'air',\n",
       "       'alcohol', 'alive', 'allowed', 'alot', 'amazing', 'amp', 'anger',\n",
       "       'angry', 'annoying', 'answer', 'antidepressant', 'anxiety',\n",
       "       'anxious', 'anybody', 'anymore', 'anyways', 'apart', 'apartment',\n",
       "       'apparently', 'appointment', 'appreciate', 'area', 'aren', 'arm',\n",
       "       'ask', 'asked', 'asking', 'asleep', 'attack', 'attempt',\n",
       "       'attempted', 'attention', 'avoid', 'awake', 'aware', 'away',\n",
       "       'awful', 'awkward', 'baby', 'bad', 'badly', 'bar', 'barely',\n",
       "       'basic', 'basically', 'bathroom', 'battle', 'bc', 'beat',\n",
       "       'beautiful', 'bed', 'begin', 'beginning', 'believe', 'best',\n",
       "       'better', 'big', 'biggest', 'bipolar', 'birthday', 'bit', 'black',\n",
       "       'blame', 'blood', 'body', 'book', 'bored', 'boring', 'born', 'bos',\n",
       "       'bother', 'bought', 'boy', 'boyfriend', 'brain', 'break',\n",
       "       'breakdown', 'breaking', 'breath', 'breathe', 'breathing', 'bring',\n",
       "       'broke', 'broken', 'brother', 'brought', 'bullied', 'bullshit',\n",
       "       'bunch', 'burden', 'business', 'busy', 'buy', 'called', 'calm',\n",
       "       'came', 'cancer', 'car', 'care', 'cared', 'career', 'case', 'cat',\n",
       "       'cause', 'caused', 'causing', 'certain', 'chance', 'change',\n",
       "       'changed', 'check', 'chest', 'child', 'childhood', 'choice',\n",
       "       'choose', 'city', 'class', 'clean', 'clear', 'close', 'coffee',\n",
       "       'cold', 'college', 'com', 'come', 'comfort', 'comfortable',\n",
       "       'coming', 'comment', 'common', 'community', 'company', 'complete',\n",
       "       'completely', 'condition', 'confidence', 'confident', 'confused',\n",
       "       'considering', 'constant', 'constantly', 'contact', 'continue',\n",
       "       'control', 'conversation', 'cool', 'cope', 'coping', 'couldn',\n",
       "       'country', 'couple', 'courage', 'course', 'covid', 'crazy',\n",
       "       'cried', 'current', 'currently', 'cut', 'cycle', 'dad', 'daily',\n",
       "       'damn', 'dark', 'date', 'dating', 'daughter', 'day', 'dead',\n",
       "       'deal', 'dealing', 'death', 'debt', 'decent', 'decide', 'decided',\n",
       "       'decision', 'deep', 'definitely', 'degree', 'depressed',\n",
       "       'depression', 'depressive', 'deserve', 'despite', 'developed',\n",
       "       'diagnosed', 'diagnosis', 'did', 'didn', 'didnt', 'die', 'died',\n",
       "       'difference', 'different', 'difficult', 'dinner', 'disease',\n",
       "       'disorder', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'doing',\n",
       "       'don', 'dont', 'door', 'dose', 'doubt', 'dread', 'dream', 'drink',\n",
       "       'drinking', 'drive', 'driving', 'drop', 'drug', 'drunk', 'dumb',\n",
       "       'dying', 'earlier', 'early', 'earth', 'easier', 'easy', 'eat',\n",
       "       'eating', 'edge', 'edit', 'effect', 'effort', 'emotion',\n",
       "       'emotional', 'emotionally', 'en', 'end', 'ended', 'ending',\n",
       "       'energy', 'english', 'enjoy', 'entire', 'episode', 'escape',\n",
       "       'especially', 'est', 'event', 'eventually', 'everybody',\n",
       "       'everyday', 'everytime', 'ex', 'exactly', 'exam', 'example',\n",
       "       'excited', 'excuse', 'exercise', 'exhausted', 'exhausting',\n",
       "       'exist', 'existence', 'expect', 'experience', 'experienced',\n",
       "       'experiencing', 'explain', 'express', 'extra', 'extreme',\n",
       "       'extremely', 'eye', 'face', 'fact', 'fail', 'failed', 'failing',\n",
       "       'failure', 'fake', 'fall', 'falling', 'family', 'far', 'fast',\n",
       "       'father', 'fault', 'fear', 'feel', 'feeling', 'fell', 'felt',\n",
       "       'fight', 'fighting', 'figure', 'final', 'finally', 'finding',\n",
       "       'fine', 'finish', 'finished', 'fit', 'fix', 'focus', 'follow',\n",
       "       'food', 'foot', 'force', 'forced', 'forever', 'forget', 'forgot',\n",
       "       'form', 'forward', 'freaking', 'free', 'friend', 'friendship',\n",
       "       'fuck', 'fucked', 'fucking', 'fully', 'fun', 'function', 'funny',\n",
       "       'future', 'game', 'gave', 'general', 'genuinely', 'getting',\n",
       "       'girl', 'girlfriend', 'given', 'giving', 'glad', 'goal', 'god',\n",
       "       'going', 'gon', 'gone', 'good', 'goodbye', 'got', 'gotten',\n",
       "       'grade', 'graduated', 'great', 'group', 'grow', 'growing', 'gt',\n",
       "       'guess', 'guilt', 'guilty', 'guy', 'gym', 'ha', 'haha', 'hair',\n",
       "       'half', 'hand', 'handle', 'hang', 'hanging', 'happen', 'happened',\n",
       "       'happening', 'happens', 'happiness', 'happy', 'hard', 'harder',\n",
       "       'harm', 'hasn', 'hate', 'haven', 'having', 'head', 'headache',\n",
       "       'health', 'healthy', 'hear', 'heard', 'heart', 'hell', 'hello',\n",
       "       'help', 'helped', 'helping', 'hey', 'hi', 'hide', 'high', 'hit',\n",
       "       'hobby', 'hold', 'holding', 'hole', 'holiday', 'home', 'homework',\n",
       "       'honest', 'honestly', 'hope', 'hopefully', 'hopeless', 'hoping',\n",
       "       'horrible', 'hospital', 'hot', 'hour', 'house', 'http', 'hug',\n",
       "       'huge', 'human', 'hurt', 'hurting', 'husband', 'idea', 'idk',\n",
       "       'ill', 'illness', 'im', 'imagine', 'immediately', 'important',\n",
       "       'impossible', 'including', 'incredibly', 'insane', 'inside',\n",
       "       'instead', 'intense', 'interested', 'interesting', 'internet',\n",
       "       'interview', 'isn', 'issue', 'ive', 'job', 'joke', 'joy', 'just',\n",
       "       'keeping', 'kept', 'kick', 'kid', 'kill', 'killed', 'killing',\n",
       "       'kind', 'kinda', 'km', 'knew', 'know', 'knowing', 'known', 'la',\n",
       "       'lack', 'late', 'lately', 'later', 'laugh', 'lay', 'lazy', 'le',\n",
       "       'lead', 'learn', 'learning', 'leave', 'leaving', 'left', 'leg',\n",
       "       'let', 'letting', 'level', 'lexapro', 'lie', 'life', 'light',\n",
       "       'like', 'likely', 'line', 'list', 'listen', 'listening',\n",
       "       'literally', 'little', 'live', 'lived', 'living', 'll', 'lol',\n",
       "       'loneliness', 'lonely', 'long', 'longer', 'look', 'looked',\n",
       "       'looking', 'lose', 'loser', 'losing', 'loss', 'lost', 'lot',\n",
       "       'loud', 'love', 'loved', 'loving', 'low', 'lt', 'luck', 'lucky',\n",
       "       'lying', 'mad', 'main', 'major', 'make', 'making', 'male', 'man',\n",
       "       'manage', 'managed', 'matter', 'maybe', 'mean', 'meaning', 'meant',\n",
       "       'med', 'medical', 'medication', 'medicine', 'medium', 'meet',\n",
       "       'meeting', 'member', 'memory', 'men', 'mental', 'mentally',\n",
       "       'mention', 'mess', 'message', 'met', 'mg', 'middle', 'mind',\n",
       "       'minute', 'mirror', 'miserable', 'miss', 'missed', 'missing',\n",
       "       'mistake', 'mizzzidc', 'mom', 'moment', 'money', 'month', 'mood',\n",
       "       'morning', 'mother', 'motivation', 'moved', 'movie', 'moving',\n",
       "       'multiple', 'mum', 'music', 'na', 'near', 'nearly', 'need',\n",
       "       'needed', 'negative', 'nervous', 'new', 'news', 'nice', 'night',\n",
       "       'nightmare', 'non', 'normal', 'note', 'notice', 'noticed', 'numb',\n",
       "       'obviously', 'ocd', 'offer', 'office', 'oh', 'ok', 'okay', 'old',\n",
       "       'older', 'omg', 'online', 'open', 'opinion', 'opportunity',\n",
       "       'option', 'order', 'outside', 'overwhelmed', 'overwhelming', 'pa',\n",
       "       'page', 'pain', 'painful', 'pandemic', 'panic', 'parent',\n",
       "       'partner', 'party', 'passed', 'past', 'pathetic', 'pay', 'peace',\n",
       "       'people', 'perfect', 'period', 'person', 'personal', 'personality',\n",
       "       'phone', 'physical', 'physically', 'pick', 'picture', 'piece',\n",
       "       'pill', 'place', 'plan', 'planning', 'play', 'playing', 'plus',\n",
       "       'pm', 'point', 'pointless', 'poor', 'positive', 'possible', 'post',\n",
       "       'posting', 'prescribed', 'pression', 'pressure', 'pretty',\n",
       "       'probably', 'problem', 'process', 'progress', 'project',\n",
       "       'properly', 'proud', 'psychiatrist', 'public', 'purpose', 'push',\n",
       "       'putting', 'question', 'quickly', 'quiet', 'quit', 'quite', 'quot',\n",
       "       'random', 'rant', 'reach', 'read', 'reading', 'ready', 'real',\n",
       "       'reality', 'realize', 'realized', 'really', 'reason', 'recently',\n",
       "       'reddit', 'regret', 'relate', 'related', 'relationship',\n",
       "       'remember', 'reply', 'response', 'rest', 'result', 'rid', 'right',\n",
       "       'rn', 'room', 'ruin', 'ruined', 'run', 'running', 'sad', 'sadness',\n",
       "       'safe', 'said', 'sat', 'saw', 'say', 'saying', 'scare', 'scared',\n",
       "       'scary', 'school', 'second', 'seeing', 'seen', 'self', 'selfish',\n",
       "       'semester', 'send', 'sense', 'sent', 'seriously', 'session', 'set',\n",
       "       'severe', 'sex', 'shake', 'shaking', 'share', 'shit', 'shitty',\n",
       "       'shoe', 'short', 'shouldn', 'shower', 'shut', 'sick', 'sign',\n",
       "       'similar', 'simple', 'simply', 'single', 'sister', 'sit',\n",
       "       'sitting', 'situation', 'skin', 'sleep', 'sleeping', 'slow',\n",
       "       'slowly', 'small', 'smart', 'smile', 'smoke', 'smoking', 'social',\n",
       "       'society', 'solution', 'somebody', 'somewhat', 'son', 'song',\n",
       "       'soon', 'sorry', 'sort', 'soul', 'sound', 'space', 'speak',\n",
       "       'spend', 'spent', 'spiral', 'spot', 'stand', 'start', 'started',\n",
       "       'starting', 'state', 'stay', 'stayed', 'staying', 'step',\n",
       "       'stomach', 'stop', 'stopped', 'store', 'story', 'straight',\n",
       "       'stress', 'stressed', 'stressful', 'strong', 'struggle',\n",
       "       'struggled', 'struggling', 'stuck', 'student', 'study', 'studying',\n",
       "       'stuff', 'stupid', 'stutter', 'sub', 'suck', 'suddenly', 'suffer',\n",
       "       'suffered', 'suffering', 'suicidal', 'suicide', 'summer', 'sun',\n",
       "       'super', 'support', 'supposed', 'sure', 'survive', 'sweet',\n",
       "       'symptom', 'ta', 'taken', 'taking', 'talk', 'talked', 'talking',\n",
       "       'task', 'teacher', 'team', 'tear', 'tell', 'telling', 'term',\n",
       "       'terrible', 'terrified', 'test', 'text', 'th', 'thank', 'thanks',\n",
       "       'thats', 'theekween', 'thelmasherbs', 'therapist', 'therapy',\n",
       "       'thing', 'think', 'thinking', 'tho', 'thought', 'throat', 'throw',\n",
       "       'till', 'time', 'tip', 'tired', 'today', 'told', 'tomorrow', 'ton',\n",
       "       'tonight', 'took', 'totally', 'tough', 'town', 'toxic', 'train',\n",
       "       'trapped', 'trauma', 'traumatic', 'treat', 'treated', 'treatment',\n",
       "       'tried', 'trigger', 'trip', 'trouble', 'true', 'truly', 'trust',\n",
       "       'truth', 'try', 'trying', 'turn', 'turned', 'tweet', 'twice',\n",
       "       'twitter', 'type', 'ugh', 'ugly', 'unable', 'uncomfortable',\n",
       "       'understand', 'understanding', 'unfortunately', 'uni',\n",
       "       'university', 'unless', 'update', 'upset', 'ur', 'urge', 'use',\n",
       "       'used', 'useless', 'using', 'usual', 'usually', 've', 'vent',\n",
       "       'video', 'view', 'voice', 'wa', 'wait', 'waiting', 'wake',\n",
       "       'waking', 'walk', 'walking', 'wall', 'wan', 'want', 'wanted',\n",
       "       'wanting', 'wasn', 'waste', 'wasted', 'watch', 'watching', 'water',\n",
       "       'way', 'weak', 'weed', 'week', 'weekend', 'weight', 'weird',\n",
       "       'went', 'weren', 'wife', 'window', 'wish', 'woke', 'woman', 'won',\n",
       "       'wonder', 'wondering', 'wont', 'word', 'work', 'worked', 'working',\n",
       "       'world', 'worried', 'worry', 'worrying', 'worse', 'worst', 'worth',\n",
       "       'worthless', 'wouldn', 'write', 'writing', 'wrong', 'wrote', 'www',\n",
       "       'yeah', 'year', 'yes', 'yesterday', 'young', 'younger', 'zoloft'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the extracted features during the vectorization\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topn_features(X, feature_names, topn=10):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X: feature matrix\n",
    "        feature_names: extracted features during vectorization\n",
    "        topn: the number of most frequent features to return\n",
    "    Outputs:\n",
    "        topn most frequent features and their frequency\n",
    "    \"\"\"\n",
    "    feature_ct = np.asarray(np.sum(X, axis=0)).reshape(-1)\n",
    "\n",
    "    feature_freq = []\n",
    "    \n",
    "    for i in np.argsort(feature_ct)[::-1][:topn]:\n",
    "        feature_freq.append({'feature':feature_names[i], 'frequency':feature_ct[i]})\n",
    "    \n",
    "    return pd.DataFrame(feature_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just</td>\n",
       "      <td>4527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wa</td>\n",
       "      <td>3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>3584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel</td>\n",
       "      <td>3227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>don</td>\n",
       "      <td>3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>want</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>know</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>life</td>\n",
       "      <td>2147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ve</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>day</td>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>people</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>really</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thing</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>year</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>friend</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>think</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>going</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  frequency\n",
       "0         just       4527\n",
       "1           wa       3810\n",
       "2         like       3584\n",
       "3         feel       3227\n",
       "4          don       3029\n",
       "5         want       2292\n",
       "6         know       2283\n",
       "7         life       2147\n",
       "8           ve       2096\n",
       "9         time       2070\n",
       "10         day       1688\n",
       "11      people       1660\n",
       "12      really       1617\n",
       "13  depression       1569\n",
       "14     anxiety       1548\n",
       "15       thing       1534\n",
       "16        year       1438\n",
       "17      friend       1297\n",
       "18       think       1280\n",
       "19       going       1252"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topn_features(X, feature_names, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the corpus in order to use it in the model later\n",
    "matrix_CV = vectorizer.fit_transform(text_lst).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CV = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TfidfVectorizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), min_df=10, max_df=0.8, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7731, 1000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer2.fit_transform(text_lst)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'absolutely', 'abuse', 'abusive', 'accept', 'accident',\n",
       "       'account', 'act', 'action', 'actually', 'add', 'adhd', 'adult',\n",
       "       'advice', 'affect', 'afford', 'afraid', 'age', 'ago', 'air',\n",
       "       'alcohol', 'alive', 'allowed', 'alot', 'amazing', 'amp', 'anger',\n",
       "       'angry', 'annoying', 'answer', 'antidepressant', 'anxiety',\n",
       "       'anxious', 'anybody', 'anymore', 'anyways', 'apart', 'apartment',\n",
       "       'apparently', 'appointment', 'appreciate', 'area', 'aren', 'arm',\n",
       "       'ask', 'asked', 'asking', 'asleep', 'attack', 'attempt',\n",
       "       'attempted', 'attention', 'avoid', 'awake', 'aware', 'away',\n",
       "       'awful', 'awkward', 'baby', 'bad', 'badly', 'bar', 'barely',\n",
       "       'basic', 'basically', 'bathroom', 'battle', 'bc', 'beat',\n",
       "       'beautiful', 'bed', 'begin', 'beginning', 'believe', 'best',\n",
       "       'better', 'big', 'biggest', 'bipolar', 'birthday', 'bit', 'black',\n",
       "       'blame', 'blood', 'body', 'book', 'bored', 'boring', 'born', 'bos',\n",
       "       'bother', 'bought', 'boy', 'boyfriend', 'brain', 'break',\n",
       "       'breakdown', 'breaking', 'breath', 'breathe', 'breathing', 'bring',\n",
       "       'broke', 'broken', 'brother', 'brought', 'bullied', 'bullshit',\n",
       "       'bunch', 'burden', 'business', 'busy', 'buy', 'called', 'calm',\n",
       "       'came', 'cancer', 'car', 'care', 'cared', 'career', 'case', 'cat',\n",
       "       'cause', 'caused', 'causing', 'certain', 'chance', 'change',\n",
       "       'changed', 'check', 'chest', 'child', 'childhood', 'choice',\n",
       "       'choose', 'city', 'class', 'clean', 'clear', 'close', 'coffee',\n",
       "       'cold', 'college', 'com', 'come', 'comfort', 'comfortable',\n",
       "       'coming', 'comment', 'common', 'community', 'company', 'complete',\n",
       "       'completely', 'condition', 'confidence', 'confident', 'confused',\n",
       "       'considering', 'constant', 'constantly', 'contact', 'continue',\n",
       "       'control', 'conversation', 'cool', 'cope', 'coping', 'couldn',\n",
       "       'country', 'couple', 'courage', 'course', 'covid', 'crazy',\n",
       "       'cried', 'current', 'currently', 'cut', 'cycle', 'dad', 'daily',\n",
       "       'damn', 'dark', 'date', 'dating', 'daughter', 'day', 'dead',\n",
       "       'deal', 'dealing', 'death', 'debt', 'decent', 'decide', 'decided',\n",
       "       'decision', 'deep', 'definitely', 'degree', 'depressed',\n",
       "       'depression', 'depressive', 'deserve', 'despite', 'developed',\n",
       "       'diagnosed', 'diagnosis', 'did', 'didn', 'didnt', 'die', 'died',\n",
       "       'difference', 'different', 'difficult', 'dinner', 'disease',\n",
       "       'disorder', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'doing',\n",
       "       'don', 'dont', 'door', 'dose', 'doubt', 'dread', 'dream', 'drink',\n",
       "       'drinking', 'drive', 'driving', 'drop', 'drug', 'drunk', 'dumb',\n",
       "       'dying', 'earlier', 'early', 'earth', 'easier', 'easy', 'eat',\n",
       "       'eating', 'edge', 'edit', 'effect', 'effort', 'emotion',\n",
       "       'emotional', 'emotionally', 'en', 'end', 'ended', 'ending',\n",
       "       'energy', 'english', 'enjoy', 'entire', 'episode', 'escape',\n",
       "       'especially', 'est', 'event', 'eventually', 'everybody',\n",
       "       'everyday', 'everytime', 'ex', 'exactly', 'exam', 'example',\n",
       "       'excited', 'excuse', 'exercise', 'exhausted', 'exhausting',\n",
       "       'exist', 'existence', 'expect', 'experience', 'experienced',\n",
       "       'experiencing', 'explain', 'express', 'extra', 'extreme',\n",
       "       'extremely', 'eye', 'face', 'fact', 'fail', 'failed', 'failing',\n",
       "       'failure', 'fake', 'fall', 'falling', 'family', 'far', 'fast',\n",
       "       'father', 'fault', 'fear', 'feel', 'feeling', 'fell', 'felt',\n",
       "       'fight', 'fighting', 'figure', 'final', 'finally', 'finding',\n",
       "       'fine', 'finish', 'finished', 'fit', 'fix', 'focus', 'follow',\n",
       "       'food', 'foot', 'force', 'forced', 'forever', 'forget', 'forgot',\n",
       "       'form', 'forward', 'freaking', 'free', 'friend', 'friendship',\n",
       "       'fuck', 'fucked', 'fucking', 'fully', 'fun', 'function', 'funny',\n",
       "       'future', 'game', 'gave', 'general', 'genuinely', 'getting',\n",
       "       'girl', 'girlfriend', 'given', 'giving', 'glad', 'goal', 'god',\n",
       "       'going', 'gon', 'gone', 'good', 'goodbye', 'got', 'gotten',\n",
       "       'grade', 'graduated', 'great', 'group', 'grow', 'growing', 'gt',\n",
       "       'guess', 'guilt', 'guilty', 'guy', 'gym', 'ha', 'haha', 'hair',\n",
       "       'half', 'hand', 'handle', 'hang', 'hanging', 'happen', 'happened',\n",
       "       'happening', 'happens', 'happiness', 'happy', 'hard', 'harder',\n",
       "       'harm', 'hasn', 'hate', 'haven', 'having', 'head', 'headache',\n",
       "       'health', 'healthy', 'hear', 'heard', 'heart', 'hell', 'hello',\n",
       "       'help', 'helped', 'helping', 'hey', 'hi', 'hide', 'high', 'hit',\n",
       "       'hobby', 'hold', 'holding', 'hole', 'holiday', 'home', 'homework',\n",
       "       'honest', 'honestly', 'hope', 'hopefully', 'hopeless', 'hoping',\n",
       "       'horrible', 'hospital', 'hot', 'hour', 'house', 'http', 'hug',\n",
       "       'huge', 'human', 'hurt', 'hurting', 'husband', 'idea', 'idk',\n",
       "       'ill', 'illness', 'im', 'imagine', 'immediately', 'important',\n",
       "       'impossible', 'including', 'incredibly', 'insane', 'inside',\n",
       "       'instead', 'intense', 'interested', 'interesting', 'internet',\n",
       "       'interview', 'isn', 'issue', 'ive', 'job', 'joke', 'joy', 'just',\n",
       "       'keeping', 'kept', 'kick', 'kid', 'kill', 'killed', 'killing',\n",
       "       'kind', 'kinda', 'km', 'knew', 'know', 'knowing', 'known', 'la',\n",
       "       'lack', 'late', 'lately', 'later', 'laugh', 'lay', 'lazy', 'le',\n",
       "       'lead', 'learn', 'learning', 'leave', 'leaving', 'left', 'leg',\n",
       "       'let', 'letting', 'level', 'lexapro', 'lie', 'life', 'light',\n",
       "       'like', 'likely', 'line', 'list', 'listen', 'listening',\n",
       "       'literally', 'little', 'live', 'lived', 'living', 'll', 'lol',\n",
       "       'loneliness', 'lonely', 'long', 'longer', 'look', 'looked',\n",
       "       'looking', 'lose', 'loser', 'losing', 'loss', 'lost', 'lot',\n",
       "       'loud', 'love', 'loved', 'loving', 'low', 'lt', 'luck', 'lucky',\n",
       "       'lying', 'mad', 'main', 'major', 'make', 'making', 'male', 'man',\n",
       "       'manage', 'managed', 'matter', 'maybe', 'mean', 'meaning', 'meant',\n",
       "       'med', 'medical', 'medication', 'medicine', 'medium', 'meet',\n",
       "       'meeting', 'member', 'memory', 'men', 'mental', 'mentally',\n",
       "       'mention', 'mess', 'message', 'met', 'mg', 'middle', 'mind',\n",
       "       'minute', 'mirror', 'miserable', 'miss', 'missed', 'missing',\n",
       "       'mistake', 'mizzzidc', 'mom', 'moment', 'money', 'month', 'mood',\n",
       "       'morning', 'mother', 'motivation', 'moved', 'movie', 'moving',\n",
       "       'multiple', 'mum', 'music', 'na', 'near', 'nearly', 'need',\n",
       "       'needed', 'negative', 'nervous', 'new', 'news', 'nice', 'night',\n",
       "       'nightmare', 'non', 'normal', 'note', 'notice', 'noticed', 'numb',\n",
       "       'obviously', 'ocd', 'offer', 'office', 'oh', 'ok', 'okay', 'old',\n",
       "       'older', 'omg', 'online', 'open', 'opinion', 'opportunity',\n",
       "       'option', 'order', 'outside', 'overwhelmed', 'overwhelming', 'pa',\n",
       "       'page', 'pain', 'painful', 'pandemic', 'panic', 'parent',\n",
       "       'partner', 'party', 'passed', 'past', 'pathetic', 'pay', 'peace',\n",
       "       'people', 'perfect', 'period', 'person', 'personal', 'personality',\n",
       "       'phone', 'physical', 'physically', 'pick', 'picture', 'piece',\n",
       "       'pill', 'place', 'plan', 'planning', 'play', 'playing', 'plus',\n",
       "       'pm', 'point', 'pointless', 'poor', 'positive', 'possible', 'post',\n",
       "       'posting', 'prescribed', 'pression', 'pressure', 'pretty',\n",
       "       'probably', 'problem', 'process', 'progress', 'project',\n",
       "       'properly', 'proud', 'psychiatrist', 'public', 'purpose', 'push',\n",
       "       'putting', 'question', 'quickly', 'quiet', 'quit', 'quite', 'quot',\n",
       "       'random', 'rant', 'reach', 'read', 'reading', 'ready', 'real',\n",
       "       'reality', 'realize', 'realized', 'really', 'reason', 'recently',\n",
       "       'reddit', 'regret', 'relate', 'related', 'relationship',\n",
       "       'remember', 'reply', 'response', 'rest', 'result', 'rid', 'right',\n",
       "       'rn', 'room', 'ruin', 'ruined', 'run', 'running', 'sad', 'sadness',\n",
       "       'safe', 'said', 'sat', 'saw', 'say', 'saying', 'scare', 'scared',\n",
       "       'scary', 'school', 'second', 'seeing', 'seen', 'self', 'selfish',\n",
       "       'semester', 'send', 'sense', 'sent', 'seriously', 'session', 'set',\n",
       "       'severe', 'sex', 'shake', 'shaking', 'share', 'shit', 'shitty',\n",
       "       'shoe', 'short', 'shouldn', 'shower', 'shut', 'sick', 'sign',\n",
       "       'similar', 'simple', 'simply', 'single', 'sister', 'sit',\n",
       "       'sitting', 'situation', 'skin', 'sleep', 'sleeping', 'slow',\n",
       "       'slowly', 'small', 'smart', 'smile', 'smoke', 'smoking', 'social',\n",
       "       'society', 'solution', 'somebody', 'somewhat', 'son', 'song',\n",
       "       'soon', 'sorry', 'sort', 'soul', 'sound', 'space', 'speak',\n",
       "       'spend', 'spent', 'spiral', 'spot', 'stand', 'start', 'started',\n",
       "       'starting', 'state', 'stay', 'stayed', 'staying', 'step',\n",
       "       'stomach', 'stop', 'stopped', 'store', 'story', 'straight',\n",
       "       'stress', 'stressed', 'stressful', 'strong', 'struggle',\n",
       "       'struggled', 'struggling', 'stuck', 'student', 'study', 'studying',\n",
       "       'stuff', 'stupid', 'stutter', 'sub', 'suck', 'suddenly', 'suffer',\n",
       "       'suffered', 'suffering', 'suicidal', 'suicide', 'summer', 'sun',\n",
       "       'super', 'support', 'supposed', 'sure', 'survive', 'sweet',\n",
       "       'symptom', 'ta', 'taken', 'taking', 'talk', 'talked', 'talking',\n",
       "       'task', 'teacher', 'team', 'tear', 'tell', 'telling', 'term',\n",
       "       'terrible', 'terrified', 'test', 'text', 'th', 'thank', 'thanks',\n",
       "       'thats', 'theekween', 'thelmasherbs', 'therapist', 'therapy',\n",
       "       'thing', 'think', 'thinking', 'tho', 'thought', 'throat', 'throw',\n",
       "       'till', 'time', 'tip', 'tired', 'today', 'told', 'tomorrow', 'ton',\n",
       "       'tonight', 'took', 'totally', 'tough', 'town', 'toxic', 'train',\n",
       "       'trapped', 'trauma', 'traumatic', 'treat', 'treated', 'treatment',\n",
       "       'tried', 'trigger', 'trip', 'trouble', 'true', 'truly', 'trust',\n",
       "       'truth', 'try', 'trying', 'turn', 'turned', 'tweet', 'twice',\n",
       "       'twitter', 'type', 'ugh', 'ugly', 'unable', 'uncomfortable',\n",
       "       'understand', 'understanding', 'unfortunately', 'uni',\n",
       "       'university', 'unless', 'update', 'upset', 'ur', 'urge', 'use',\n",
       "       'used', 'useless', 'using', 'usual', 'usually', 've', 'vent',\n",
       "       'video', 'view', 'voice', 'wa', 'wait', 'waiting', 'wake',\n",
       "       'waking', 'walk', 'walking', 'wall', 'wan', 'want', 'wanted',\n",
       "       'wanting', 'wasn', 'waste', 'wasted', 'watch', 'watching', 'water',\n",
       "       'way', 'weak', 'weed', 'week', 'weekend', 'weight', 'weird',\n",
       "       'went', 'weren', 'wife', 'window', 'wish', 'woke', 'woman', 'won',\n",
       "       'wonder', 'wondering', 'wont', 'word', 'work', 'worked', 'working',\n",
       "       'world', 'worried', 'worry', 'worrying', 'worse', 'worst', 'worth',\n",
       "       'worthless', 'wouldn', 'write', 'writing', 'wrong', 'wrote', 'www',\n",
       "       'yeah', 'year', 'yes', 'yesterday', 'young', 'younger', 'zoloft'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF = pd.DataFrame(X.toarray(), columns=vectorizer2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the corpus in order to use it in the model later\n",
    "matrix2_TF = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### CountVectorizer Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5411, 1000), (2320, 1000))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Get the input feature matrix and target variable, prepare for model fitting\n",
    "x1 = matrix_CV\n",
    "y1 = df['is_depression']\n",
    "x1.shape, y1.shape\n",
    "# split the data into training and testing set\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.3, random_state=42)\n",
    "x1_train.shape, x1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression model without any regularization\n",
    "lg_None = LogisticRegression(random_state=0, solver='liblinear',).fit(x1_train, y1_train)\n",
    "score1 = np.round(lg_None.score(x1_test, y1_test), 3)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression model with L1 regularization\n",
    "lg_L1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1').fit(x1_train, y1_train)\n",
    "score2 = np.round(lg_L1.score(x1_test, y1_test), 3)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression model with L2 regularization\n",
    "lg_L2 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2').fit(x1_train, y1_train)\n",
    "score3 = np.round(lg_L2.score(x1_test, y1_test), 3)\n",
    "score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the class weight to balanced\n",
    "lg_1 = LogisticRegression(random_state=0, solver='liblinear', class_weight='balanced').fit(x1_train, y1_train)\n",
    "score4 = np.round(lg_1.score(x1_test, y1_test), 3)\n",
    "score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not fit intercept \n",
    "lg_2 = LogisticRegression(random_state=0, solver='liblinear', fit_intercept=False).fit(x1_train, y1_train)\n",
    "score5 = np.round(lg_2.score(x1_test, y1_test), 3)\n",
    "score5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.952, 0.947, 0.925)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different complexity of the model\n",
    "lg_3 = LogisticRegression(random_state=0, solver='liblinear', C=0.1).fit(x1_train, y1_train)\n",
    "score6 = np.round(lg_3.score(x1_test, y1_test), 3)\n",
    "lg_4 = LogisticRegression(random_state=0, solver='liblinear', C=10).fit(x1_train, y1_train)\n",
    "score7 = np.round(lg_4.score(x1_test, y1_test), 3)\n",
    "lg_5 = LogisticRegression(random_state=0, solver='liblinear', C=100).fit(x1_train, y1_train)\n",
    "score8 = np.round(lg_5.score(x1_test, y1_test), 3)\n",
    "score6, score7, score8  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### TfidfVectorizer Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5411, 1000), (2320, 1000))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Get the input feature matrix and target variable, prepare for model fitting\n",
    "x2 = matrix2_TF\n",
    "y2 = df['is_depression']\n",
    "x2.shape, y2.shape\n",
    "# split the data into training and testing set\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x1, y1, test_size=0.3, random_state=42)\n",
    "x2_train.shape, x2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression model without any regularization\n",
    "lg_tf_None = LogisticRegression(random_state=0, solver='liblinear',).fit(x2_train, y2_train)\n",
    "score9 = np.round(lg_tf_None.score(x2_test, y2_test), 3)\n",
    "score9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression model with L1 regularization\n",
    "lg_tf_L1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1').fit(x2_train, y2_train)\n",
    "score10 = np.round(lg_tf_L1.score(x2_test, y2_test), 3)\n",
    "score9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression model with L2 regularization\n",
    "lg_tf_L2 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2').fit(x2_train, y2_train)\n",
    "score11 = np.round(lg_tf_L2.score(x2_test, y2_test), 3)\n",
    "score11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the class weight to balanced\n",
    "lg_tf_1 = LogisticRegression(random_state=0, solver='liblinear', class_weight='balanced').fit(x2_train, y2_train)\n",
    "score12 = np.round(lg_tf_1.score(x2_test, y2_test), 3)\n",
    "score12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not fit intercept \n",
    "lg_tf_L1 = LogisticRegression(random_state=0, solver='liblinear', fit_intercept=False).fit(x2_train, y2_train)\n",
    "score13 = np.round(lg_tf_L1.score(x2_test, y2_test), 3)\n",
    "score13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.952, 0.947, 0.925)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different complexity of the model\n",
    "lg_tf_L2 = LogisticRegression(random_state=0, solver='liblinear', C=0.1).fit(x2_train, y2_train)\n",
    "score14 = np.round(lg_tf_L2.score(x2_test, y2_test), 3)\n",
    "lg_tf_L3 = LogisticRegression(random_state=0, solver='liblinear', C=10).fit(x2_train, y2_train)\n",
    "score15 = np.round(lg_tf_L3.score(x2_test, y2_test), 3)\n",
    "lg_tf_L4 = LogisticRegression(random_state=0, solver='liblinear', C=100).fit(x2_train, y2_train)\n",
    "score16 = np.round(lg_tf_L4.score(x2_test, y2_test), 3)\n",
    "score14, score15, score16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After performing various logistic regression models by adjusting penalties, complexity, and balanced weights, it became evident that the default settings actually yield the best results for our sample. \n",
    "- Moreover, the TfidfVectorizer and CountVectorizer exhibit no substantial differences; this finding aligns with results observed when fitting tree models. When compared to tree models, logistic regression demonstrates an overall superior performance. This can be attributed to its ability to handle both binary classification efficiently. \n",
    "- Finally, the reason why logistic regression outperforms other models overall lies in the nature of the question I sought to address with this dataset: building a depression detection model based on textual data. Given that this is a classic classification scenario with a binary dependent variable, logistic regression emerges as an ideal choice. Its ability to predict the likelihood of depression for each text entry makes it particularly well-suited for this task, thus solidifying its superiority in addressing the underlying question.\n",
    "\n",
    "### Additionally, logistic regression offers several advantages:\n",
    "\n",
    "Pros:\n",
    "- Regularization: By adjusting L1 and L2 penalties, logistic regression can effectively prevent overfitting and improve generalization performance.\n",
    "- Probability Estimation: Logistic regression outputs probabilities of class membership, enabling decision-making based on confidence levels.\n",
    "- the complexity parameter 'C' in logistic regression provides a means to control the balance between model complexity and generalization performance, allowing practitioners to tailor the model to the specific characteristics of the dataset and the problem at hand.\n",
    "\n",
    "Cons:\n",
    "- Assumption of Linearity: Logistic regression assumes a linear relationship between predictor variables, which may not always hold true in practice.\n",
    "- Logistic regression is less flexible in capturing complex, non-linear relationships compared to some other machine learning algorithms.\n",
    "- High multicollinearity among predictor variables can lead to unstable coefficient estimates and reduced interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
